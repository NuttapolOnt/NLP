{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancel)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming) \n",
        "\n",
        "In this homework, you are asked to do the following tasks:\n",
        "1. Data Cleaning\n",
        "2. Preprocessing data for pytorch\n",
        "3. Build and evaluate a model for \"action\" classification\n",
        "4. Build and evaluate a model for \"object\" classification\n",
        "5. Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go \n",
        "\n",
        "\n",
        "Note: we have removed phone numbers from the dataset for privacy purposes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHqkFSyaNvOt",
        "outputId": "bf14de5e-37a9-43bd-e382-adac9fcf8a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-02-26 12:42:32--  https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/37u83g55p19kvrl/clean-phone-data-for-students.csv [following]\n",
            "--2023-02-26 12:42:32--  https://www.dropbox.com/s/raw/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com/cd/0/inline/B3P_WxkRmHfN0ZFCcX_2Ffk4eXNICPOytNjq0ViCnzdn0Bj3IN6Ih2QXri-4K-TlMpUQ8Q66VAyR7Sb1Tfx6_Tr9Z5vSC5N3U2-oYfrYxDPQwQ36eNRcN7-JDo8HCq--6u55-R_lP_aDLJvIwySw2PLKfkPw6UkvpE0OftNt6voVdQ/file# [following]\n",
            "--2023-02-26 12:42:32--  https://ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com/cd/0/inline/B3P_WxkRmHfN0ZFCcX_2Ffk4eXNICPOytNjq0ViCnzdn0Bj3IN6Ih2QXri-4K-TlMpUQ8Q66VAyR7Sb1Tfx6_Tr9Z5vSC5N3U2-oYfrYxDPQwQ36eNRcN7-JDo8HCq--6u55-R_lP_aDLJvIwySw2PLKfkPw6UkvpE0OftNt6voVdQ/file\n",
            "Resolving ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com (ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com (ucb0ea74e3b0a9bcd634831ebbb4.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2518977 (2.4M) [text/plain]\n",
            "Saving to: ‘clean-phone-data-for-students.csv.4’\n",
            "\n",
            "clean-phone-data-fo 100%[===================>]   2.40M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-02-26 12:42:32 (31.2 MB/s) - ‘clean-phone-data-for-students.csv.4’ saved [2518977/2518977]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "11456a23-a0b3-42bf-937b-65666f789529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.8/dist-packages (3.1.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from pythainlp) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd \n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje3yruTMc5p"
      },
      "source": [
        "Let's preview the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "aNqRNz1PMc5q",
        "outputId": "f4919896-bfd8-4ee9-9542-435b06daa428"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>package</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
              "      <td>report</td>\n",
              "      <td>suspend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
              "      <td>report</td>\n",
              "      <td>phone_issues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Sentence Utterance   Action        Object\n",
              "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
              "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
              "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
              "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
              "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the top 5 rows\n",
        "display(data_df.head())\n",
        "# Summarize the data\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 1: \n",
        "You will have to remove unwanted label duplications as well as duplications in text inputs. \n",
        "Also, you will have to trim out unwanted whitespaces from the text inputs. \n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V0bGLblVMc5z",
        "outputId": "e4348814-3062-4ad8-8ac8-adb8fe3073f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
              "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
              "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
              "       'Loyalty_card'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'Enquire', 'buy', 'activate',\n",
              "       'request', 'Report', 'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "19onNNUZMc54",
        "outputId": "0ca79412-3037-4e59-a1cf-bba71146d04b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13389</td>\n",
              "      <td>13389</td>\n",
              "      <td>13389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>8</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>8658</td>\n",
              "      <td>2111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Sentence Utterance   Action   Object\n",
              "count                                               13389    13389    13389\n",
              "unique                                              13389        8       26\n",
              "top      <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire  service\n",
              "freq                                                    1     8658     2111"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n",
              "       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'buy', 'activate', 'request',\n",
              "       'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO1: Data cleaning\n",
        "data_df['Action'] = data_df['Action'].str.lower()\n",
        "data_df['Object'] = data_df['Object'].str.lower()\n",
        "data_df = data_df.drop_duplicates(subset=['Sentence Utterance'])\n",
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLozhPWFgwDN",
        "outputId": "de2f49a5-3da3-4733-cf2d-4acb719751c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท',\n",
              "        'enquire', 'payment'],\n",
              "       ['internet ยังความเร็วอยุ่เท่าไหร ครับ', 'enquire', 'package'],\n",
              "       ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ', 'report',\n",
              "        'suspend'],\n",
              "       ['พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อง โกลไล',\n",
              "        'enquire', 'internet'],\n",
              "       ['ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโทรออกไม่ได้คะ แต่เล่นเนตได้คะ',\n",
              "        'report', 'phone_issues'],\n",
              "       ['*2222 ใช้งานยังไง ขอรายละเอียดการสมัครหน่อย', 'enquire',\n",
              "        'service'],\n",
              "       ['<PHONE_NUMBER_REMOVED> เคยมีช่างมาซ่อมที่บ้าน แล้วโทรศัพท์ใช้งานไม่ได้ครับ',\n",
              "        'enquire', 'nontruemove'],\n",
              "       ['<PHONE_NUMBER_REMOVED> ค้างค่าบริการเท่าไหร่ครับ', 'enquire',\n",
              "        'balance'],\n",
              "       ['<PHONE_NUMBER_REMOVED> อินเตอร์เน็ตไฟ Adsl ไม่มีสัญญาณครับ',\n",
              "        'enquire', 'nontruemove'],\n",
              "       ['<PHONE_NUMBER_REMOVED> เค้าบอกจะส่งรหัสเน็ตมาให้ แต่ยังไม่ได้ส่งมาเลยค่ะ',\n",
              "        'enquire', 'internet']], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data_df.to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo1YByXlzr67"
      },
      "source": [
        "## TODO2 : Assign index to word and labels in each sentences. \n",
        "\n",
        "Note that please use **word_tokenize** (https://pythainlp.github.io/docs/2.0/api/tokenize.html) as a function to tokenize each sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "crwlkeMVyHh_",
        "outputId": "c6e233bb-781b-4076-8321-2d4dd0128410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท',\n",
              "        30, 17],\n",
              "       ['internet ยังความเร็วอยุ่เท่าไหร ครับ', 30, 28],\n",
              "       ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ', 31, 11],\n",
              "       ['พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อง โกลไล', 30, 19],\n",
              "       ['ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโทรออกไม่ได้คะ แต่เล่นเนตได้คะ',\n",
              "        31, 0],\n",
              "       ['*2222 ใช้งานยังไง ขอรายละเอียดการสมัครหน่อย', 30, 4],\n",
              "       ['<PHONE_NUMBER_REMOVED> เคยมีช่างมาซ่อมที่บ้าน แล้วโทรศัพท์ใช้งานไม่ได้ครับ',\n",
              "        30, 2],\n",
              "       ['<PHONE_NUMBER_REMOVED> ค้างค่าบริการเท่าไหร่ครับ', 30, 24],\n",
              "       ['<PHONE_NUMBER_REMOVED> อินเตอร์เน็ตไฟ Adsl ไม่มีสัญญาณครับ', 30,\n",
              "        2],\n",
              "       ['<PHONE_NUMBER_REMOVED> เค้าบอกจะส่งรหัสเน็ตมาให้ แต่ยังไม่ได้ส่งมาเลยค่ะ',\n",
              "        30, 19]], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO2: assign index to each words and labels in sentence. \n",
        "\n",
        "unique_object = set(data_df.Object.unique().tolist())\n",
        "unique_action = set(data_df.Action.unique().tolist())\n",
        "unique_label = unique_action.union(unique_object)\n",
        "\n",
        "label_to_idx = dict(zip(unique_label, range(len(unique_label))))\n",
        "idx_to_label = dict(zip(range(len(unique_label)), unique_label))\n",
        "\n",
        "for x in data:\n",
        "    x[-2] = label_to_idx[x[-2]]\n",
        "    x[-1] = label_to_idx[x[-1]]\n",
        "\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4soW6GG5z8L6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['<',\n",
              "  'PHONE',\n",
              "  '_',\n",
              "  'NUMBER',\n",
              "  '_',\n",
              "  'REMOVED',\n",
              "  '>',\n",
              "  'ผม',\n",
              "  'ไป',\n",
              "  'จ่าย',\n",
              "  'เงิน',\n",
              "  'ที่',\n",
              "  'Counter',\n",
              "  'Services',\n",
              "  'เค้า',\n",
              "  'เช็ต',\n",
              "  '3276.25',\n",
              "  'บาท',\n",
              "  'เมื่อวาน',\n",
              "  'ที่',\n",
              "  'ผม',\n",
              "  'เช็ค',\n",
              "  'ที่',\n",
              "  'ศูนย์',\n",
              "  'บอก',\n",
              "  'มี',\n",
              "  'ยอด',\n",
              "  '3057.79',\n",
              "  'บาท'],\n",
              " ['internet', 'ยัง', 'ความเร็ว', 'อยุ่', 'เท่า', 'ไห', 'ร', 'ครับ'],\n",
              " ['ตะกี้',\n",
              "  'ไป',\n",
              "  'ชำระ',\n",
              "  'ค่าบริการ',\n",
              "  'ไป',\n",
              "  'แล้ว',\n",
              "  'แต่',\n",
              "  'ยัง',\n",
              "  'ใช้งาน',\n",
              "  'ไม่',\n",
              "  'ได้',\n",
              "  'ค่ะ'],\n",
              " ['พี่',\n",
              "  'ค่ะ',\n",
              "  'ยัง',\n",
              "  'ใช้',\n",
              "  'internet',\n",
              "  'ไม่',\n",
              "  'ได้',\n",
              "  'เลย',\n",
              "  'ค่ะ',\n",
              "  'เป็น',\n",
              "  'เครื่อง',\n",
              "  'โก',\n",
              "  'ลไล'],\n",
              " ['ฮา',\n",
              "  'โหล',\n",
              "  'คะ',\n",
              "  'พอดี',\n",
              "  'ว่า',\n",
              "  'เมื่อวาน',\n",
              "  'เปิด',\n",
              "  'ซิม',\n",
              "  'ทรูมูฟ',\n",
              "  'แต่',\n",
              "  'มัน',\n",
              "  'โทร',\n",
              "  'ออก',\n",
              "  'ไม่',\n",
              "  'ได้',\n",
              "  'คะ',\n",
              "  'แต่',\n",
              "  'เล่น',\n",
              "  'เนต',\n",
              "  'ได้',\n",
              "  'คะ']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_data = []\n",
        "for x in data:\n",
        "  words = word_tokenize(x[0],keep_whitespace = False)\n",
        "  tokenized_data.append(words)\n",
        "tokenized_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B2Lx9nTfzZCZ"
      },
      "outputs": [],
      "source": [
        "word_to_idx ={}\n",
        "idx_to_word ={}\n",
        "\n",
        "for sentence in tokenized_data:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_idx:\n",
        "            word_to_idx[word] = len(word_to_idx)+1\n",
        "            idx_to_word[word_to_idx[word]] = word\n",
        "word_to_idx['UNK'] = len(word_to_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZX0ZiEpH8ojY"
      },
      "outputs": [],
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    if word in word_to_idx :\n",
        "        return word_to_idx[word]\n",
        "    else :\n",
        "        return word_to_idx['UNK']\n",
        "\n",
        "def sent2features(sent):\n",
        "    return np.asarray([word2features(sent, i) for i in range(len(sent))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPedisoi7-Kx",
        "outputId": "6c2e9dcd-801d-4e3d-93cf-492e90ee25e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/y1/cn0zl8b15fs9mg2fhdq6b6jc0000gn/T/ipykernel_26349/3776515774.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  dataset = np.asarray([sent2features(sent) for sent in tokenized_data])\n"
          ]
        }
      ],
      "source": [
        "dataset = np.asarray([sent2features(sent) for sent in tokenized_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwCH7Nrf84lT",
        "outputId": "6074572c-541c-4c3b-e13d-18762459ddaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([array([ 1,  2,  3,  4,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "              17, 18, 11,  7, 19, 11, 20, 21, 22, 23, 24, 17])                   ,\n",
              "       array([25, 26, 27, 28, 29, 30, 31, 32]),\n",
              "       array([33,  8, 34, 35,  8, 36, 37, 26, 38, 39, 40, 41]),\n",
              "       array([42, 41, 26, 43, 25, 39, 40, 44, 41, 45, 46, 47, 48]),\n",
              "       array([49, 50, 51, 52, 53, 18, 54, 55, 56, 37, 57, 58, 59, 39, 40, 51, 37,\n",
              "              60, 61, 40, 51])                                                   ,\n",
              "       array([62, 63, 38, 64, 65, 66, 67, 68, 69]),\n",
              "       array([ 1,  2,  3,  4,  3,  5,  6, 70, 22, 71, 72, 73, 11, 74, 36, 75, 38,\n",
              "              39, 40, 32])                                                       ,\n",
              "       array([ 1,  2,  3,  4,  3,  5,  6, 76, 35, 77, 32]),\n",
              "       array([ 1,  2,  3,  4,  3,  5,  6, 78, 79, 80, 39, 22, 81, 32]),\n",
              "       array([ 1,  2,  3,  4,  3,  5,  6, 14, 21, 82, 83, 84, 85, 72, 86, 37, 26,\n",
              "              39, 40, 83, 72, 44, 41])                                           ],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BZZYPuIMc59"
      },
      "source": [
        "## TODO 2,3: Preprocessing data for pytorch\n",
        "You will be using pytorch in this assignment. Please show us how you prepare your dataloader for pytorch.\n",
        "Don't forget to split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tYBrQCOX6tZb"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SycOJ6cDMc5_"
      },
      "outputs": [],
      "source": [
        "# TODO2: Preprocessing data for pytorch \n",
        "class TrueCallCenterDataset(Dataset):\n",
        "  def __init__(self,data,labels=None):\n",
        "    self.data = data \n",
        "    self.labels = labels\n",
        "\n",
        "    if labels is not None: \n",
        "      assert len(data) == len(labels)  \n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    if self.labels is None: \n",
        "      return torch.LongTensor(self.data[idx])\n",
        "    else: \n",
        "      return (\n",
        "          torch.LongTensor(self.data[idx]), \n",
        "          torch.LongTensor(self.labels[idx])\n",
        "      )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7Uf8UwWJkhz"
      },
      "source": [
        "\n",
        "## TODO 3: Split the data\n",
        "\n",
        "We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set. \n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train , validation, test set are similar. There is **stratify** variable handling this issue. \n",
        "\n",
        "In this case, you can choose whatever you want either \"**Action**\" or \"**Object**\" ;). \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k2NPVYj5JU1H"
      },
      "outputs": [],
      "source": [
        "# TODO3: split data into train, validation, test  \n",
        "from sklearn.model_selection import train_test_split\n",
        "random_seed = 2023\n",
        "\n",
        "x_train_action , x_nottrain_action , al_train , al_nottrain = train_test_split(dataset,data[:,1],stratify = data[:,1], test_size=0.2,random_state=random_seed)\n",
        "x_val_action , x_test_action , al_val , al_test = train_test_split(x_nottrain_action,al_nottrain, test_size=0.5,random_state=random_seed)\n",
        "\n",
        "x_train_object , x_nottrain_object , ol_train , ol_nottrain = train_test_split(dataset,data[:,2],stratify = data[:,2], test_size=0.2,random_state=random_seed)\n",
        "x_val_object , x_test_object , ol_val , ol_test = train_test_split(x_nottrain_object,ol_nottrain, test_size=0.5,random_state=random_seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKeikxDy5Ahs"
      },
      "source": [
        "## TODO 4: Build a model for classifying these texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Us46u83w5kjX"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,word_to_idx):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embed = nn.Embedding(len(word_to_idx),32)\n",
        "    self.bigru = nn.GRU(32,32,bidirectional=True,batch_first=True)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    # print(x.shape)\n",
        "    x = self.embed(x)\n",
        "    # print(x.shape)\n",
        "    out, _ = self.bigru(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Classifier,self).__init__()\n",
        "    self.dropout = nn.Dropout(0.2) \n",
        "    self.flatten = nn.Flatten()\n",
        "    self.classifier = nn.Linear(7232, 33) \n",
        "\n",
        "  def forward(self,x):\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.dropout(x))\n",
        "    # print(x.shape)\n",
        "    x = self.flatten(x)\n",
        "    # print(x.shape)\n",
        "    out = self.classifier(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,encoder,classifier):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.classifier = classifier\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.encoder(x)\n",
        "\n",
        "    x = self.classifier(x)\n",
        "\n",
        "    return x "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tXZiLZ4Mc6E"
      },
      "source": [
        "## #TODO 3: Build and evaluate a model for \"action\" classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4Dd0R-AiRvup"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[30],\n",
            "        [30],\n",
            "        [30],\n",
            "        [30],\n",
            "        [30]])\n"
          ]
        }
      ],
      "source": [
        "## TODO 3.1: prepare dataloader \n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "x_train = [torch.LongTensor(sentence) for sentence in x_train_action]\n",
        "y_train = [torch.LongTensor([label]) for label in al_train]\n",
        "x_val = [torch.LongTensor(sentence) for sentence in x_val_action]\n",
        "y_val = [torch.LongTensor([label]) for label in al_val]\n",
        "\n",
        "x_test = [torch.LongTensor(sentence) for sentence in x_test_action]\n",
        "y_test = [torch.LongTensor([label]) for label in al_test]\n",
        "\n",
        "x_train = pad_sequence(x_train, batch_first=True)\n",
        "y_train = pad_sequence(y_train, batch_first=True)\n",
        "x_val = pad_sequence(x_val, batch_first=True)\n",
        "y_val = pad_sequence(y_val, batch_first=True)\n",
        "x_test = pad_sequence(x_test, batch_first=True)\n",
        "y_test = pad_sequence(y_test, batch_first=True)\n",
        "\n",
        "maxlen = x_train.size(1)  \n",
        "\n",
        "# Pad the sequence length of x_test to be maxlen \n",
        "remaining_len = x_train.size(1) - x_test.size(1)\n",
        "remaining_mat = torch.zeros((x_test.size(0), remaining_len), dtype=torch.long) \n",
        "x_test = torch.cat((x_test, remaining_mat), dim=1) \n",
        "\n",
        "# Pad the sequence length of x_test to be maxlen \n",
        "remaining_len = x_train.size(1) - x_val.size(1)\n",
        "remaining_mat = torch.zeros((x_val.size(0), remaining_len), dtype=torch.long) \n",
        "x_val = torch.cat((x_val, remaining_mat), dim=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SjgtuECIKBpi"
      },
      "outputs": [],
      "source": [
        "train_dataset = TrueCallCenterDataset(x_train, y_train) \n",
        "val_dataset = TrueCallCenterDataset(x_val, y_val) \n",
        "test_dataset = TrueCallCenterDataset(x_test)\n",
        "\n",
        "# print(train_dataset[0])\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True) \n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True) \n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3vnhyI1R-jd",
        "outputId": "c9b3312f-5f98-43dd-d883-ae0f3d3cde57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Model                                    --\n",
            "├─Encoder: 1-1                           --\n",
            "│    └─Embedding: 2-1                    133,088\n",
            "│    └─GRU: 2-2                          12,672\n",
            "├─Classifier: 1-2                        --\n",
            "│    └─Dropout: 2-3                      --\n",
            "│    └─Flatten: 2-4                      --\n",
            "│    └─Linear: 2-5                       238,689\n",
            "=================================================================\n",
            "Total params: 384,449\n",
            "Trainable params: 384,449\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "## TODO 3.2: setup model \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = Model(Encoder(word_to_idx),Classifier()) \n",
        "model.to(device) \n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3) \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(torchinfo.summary(model))\n",
        "\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4PX4GESRx3f",
        "outputId": "35ac7561-36c3-417c-bcf8-7cd0c61b408d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoc :1, running_loss :56.82822507619858\n",
            "epoc :2, running_loss :50.37886633723974\n",
            "epoc :3, running_loss :45.00737752020359\n",
            "epoc :4, running_loss :39.55078262090683\n",
            "epoc :5, running_loss :35.78563795238733\n",
            "epoc :6, running_loss :31.510195165872574\n",
            "epoc :7, running_loss :27.336409527808428\n",
            "epoc :8, running_loss :24.814037401229143\n",
            "epoc :9, running_loss :21.664752764627337\n",
            "epoc :10, running_loss :19.505208730697632\n",
            "epoc :11, running_loss :16.821817617863417\n",
            "epoc :12, running_loss :15.120801562443376\n",
            "epoc :13, running_loss :13.319533098489046\n",
            "epoc :14, running_loss :11.993461695499718\n",
            "epoc :15, running_loss :10.370506486855447\n",
            "epoc :16, running_loss :9.328579120337963\n",
            "epoc :17, running_loss :7.728622563648969\n",
            "epoc :18, running_loss :7.189861802849919\n",
            "epoc :19, running_loss :6.620659687556326\n",
            "epoc :20, running_loss :6.242256939643994\n"
          ]
        }
      ],
      "source": [
        "## TODO 3.3: training loop\n",
        "PATH = './action_model.pth'\n",
        "min_val_loss = 1e10\n",
        "for epoch in range(1, num_epochs+1): \n",
        "  running_loss = 0.0\n",
        "  running_val_loss = 0.0\n",
        "  model.train() \n",
        "  for inputs, targets in train_dataloader: \n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    pred = model(inputs)\n",
        "    \n",
        "    targets = targets.reshape(-1)\n",
        "\n",
        "    loss = criterion(pred, targets) \n",
        "\n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  model.eval() \n",
        "  y_pred = [] \n",
        "  with torch.no_grad():\n",
        "      for i,data in enumerate(val_dataloader, 0):\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          '''\n",
        "          Insert your code here\n",
        "\n",
        "          '''\n",
        "          # print(inputs.shape)\n",
        "          preds = model(inputs)\n",
        "          labels = labels.reshape(-1)\n",
        "          loss = criterion(preds,labels)\n",
        "\n",
        "          # print(loss.grad)\n",
        "\n",
        "          running_val_loss += loss.item()\n",
        "          \n",
        "      avg_val_loss = running_val_loss/len(val_dataloader)\n",
        "\n",
        "  if avg_val_loss < min_val_loss:\n",
        "      torch.save(model.state_dict(), PATH)\n",
        "      min_val_loss = avg_val_loss\n",
        "\n",
        "  print(\"epoc :{}, running_loss :{}\".format(epoch,running_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa5bwUkG-v01",
        "outputId": "d41492dd-b979-4882-9ce1-17163ccc6edf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Model(Encoder(word_to_idx), Classifier())\n",
        "model.load_state_dict(torch.load('action_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4eM-ZeySJVb",
        "outputId": "83cd2d63-38ac-4f40-8c70-0c967f0d4ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc testing with test data: 84.91411501120238\n"
          ]
        }
      ],
      "source": [
        "## TODO 3.5: evalaute on test set \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predict = list()\n",
        "label = al_test\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_test in test_dataloader:\n",
        "        Y_pred = model(X_test)\n",
        "        _, pred = torch.max(Y_pred.data, 1)\n",
        "        for p in pred:\n",
        "            predict.append(p.item())\n",
        "\n",
        "print(\"acc testing with test data:\", sum(predict == label)/len(label) *100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq3EAx__F68Y",
        "outputId": "4838febd-36b2-45c7-817b-793b56958f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Acc. on val data 83.034378%\n"
          ]
        }
      ],
      "source": [
        "y_pred_val = model(x_val)\n",
        "print(\"Model Acc. on val data %f%%\"\n",
        "       % ((y_val.squeeze(1) == torch.argmax(y_pred_val,axis=1)).sum() / sentence_val_data_1.shape[0] * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRUK0Q8Mc6J"
      },
      "source": [
        "## #TODO 4: Build and evaluate a model for \"object\" classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "9evsrIiKMc6K"
      },
      "outputs": [],
      "source": [
        "## TODO 4.1: prepare dataloader \n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "x_train = [torch.LongTensor(sentence) for sentence in x_train_object]\n",
        "y_train_2 = [torch.LongTensor([label]) for label in ol_train]\n",
        "x_val = [torch.LongTensor(sentence) for sentence in x_val_object]\n",
        "y_val = [torch.LongTensor([label]) for label in ol_val]\n",
        "\n",
        "x_test = [torch.LongTensor(sentence) for sentence in x_test_object]\n",
        "y_test = [torch.LongTensor([label]) for label in ol_test]\n",
        "\n",
        "x_train = pad_sequence(x_train, batch_first=True)\n",
        "y_train = pad_sequence(y_train, batch_first=True)\n",
        "x_val = pad_sequence(x_val, batch_first=True)\n",
        "y_val = pad_sequence(y_val, batch_first=True)\n",
        "x_test = pad_sequence(x_test, batch_first=True)\n",
        "y_test = pad_sequence(y_test, batch_first=True)\n",
        "\n",
        "maxlen = max([x_train.size(1), x_val.size(1), x_test.size(1)])\n",
        "\n",
        "remaining_len = maxlen - x_train.size(1)\n",
        "remaining_mat = torch.zeros((x_train.size(0), remaining_len), dtype=torch.long) \n",
        "x_train = torch.cat((x_train, remaining_mat), dim=1) \n",
        "\n",
        "# Pad the sequence length of x_test to be maxlen \n",
        "remaining_len = maxlen - x_test.size(1)\n",
        "remaining_mat = torch.zeros((x_test.size(0), remaining_len), dtype=torch.long) \n",
        "x_test = torch.cat((x_test, remaining_mat), dim=1) \n",
        "\n",
        "# Pad the sequence length of x_test to be maxlen \n",
        "remaining_len = maxlen - x_val.size(1)\n",
        "remaining_mat = torch.zeros((x_val.size(0), remaining_len), dtype=torch.long) \n",
        "x_val = torch.cat((x_val, remaining_mat), dim=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "e0OTJ7c6I4kO"
      },
      "outputs": [],
      "source": [
        "train_dataset = TrueCallCenterDataset(x_train, y_train) \n",
        "val_dataset = TrueCallCenterDataset(x_val, y_val) \n",
        "test_dataset = TrueCallCenterDataset(x_test)\n",
        "\n",
        "# print(train_dataset[0])\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True) \n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True) \n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwBr5YHTJxh",
        "outputId": "736654a8-588c-425e-a6a4-e41bcc78b2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Model                                    --\n",
            "├─Encoder: 1-1                           --\n",
            "│    └─Embedding: 2-1                    133,088\n",
            "│    └─GRU: 2-2                          12,672\n",
            "├─Classifier: 1-2                        --\n",
            "│    └─Dropout: 2-3                      --\n",
            "│    └─Flatten: 2-4                      --\n",
            "│    └─Linear: 2-5                       238,689\n",
            "=================================================================\n",
            "Total params: 384,449\n",
            "Trainable params: 384,449\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "## TODO 4.2: setup model \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model2 = Model(Encoder(word_to_idx),Classifier()) \n",
        "model2.to(device) \n",
        "\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3) \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(torchinfo.summary(model2))\n",
        "\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqf4m3C8TLBk",
        "outputId": "7f7b4063-19d0-4f26-9436-9bb55d2b17eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoc :1, running_loss :268.4608509540558\n",
            "epoc :2, running_loss :206.9984848499298\n",
            "epoc :3, running_loss :174.43016189336777\n",
            "epoc :4, running_loss :150.39867055416107\n",
            "epoc :5, running_loss :134.20238164067268\n",
            "epoc :6, running_loss :118.51393008232117\n",
            "epoc :7, running_loss :106.38608959317207\n",
            "epoc :8, running_loss :95.52411434054375\n",
            "epoc :9, running_loss :87.53812626004219\n",
            "epoc :10, running_loss :77.95145598053932\n",
            "epoc :11, running_loss :69.765764772892\n",
            "epoc :12, running_loss :63.28580106794834\n",
            "epoc :13, running_loss :57.122556924819946\n",
            "epoc :14, running_loss :51.275114350020885\n",
            "epoc :15, running_loss :46.35949873179197\n",
            "epoc :16, running_loss :41.33680732548237\n",
            "epoc :17, running_loss :37.29395304620266\n",
            "epoc :18, running_loss :33.83821315318346\n",
            "epoc :19, running_loss :30.9090263992548\n",
            "epoc :20, running_loss :27.744039051234722\n"
          ]
        }
      ],
      "source": [
        "## TODO 4.3: training loop\n",
        "PATH = './object_model.pth'\n",
        "min_val_loss = 1e10\n",
        "for epoch in range(1, num_epochs+1): \n",
        "  running_loss = 0.0\n",
        "  running_val_loss = 0.0\n",
        "  model2.train() \n",
        "  for inputs, targets in train_dataloader: \n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    pred = model2(inputs)\n",
        "    \n",
        "    targets = targets.reshape(-1)\n",
        "\n",
        "    loss = criterion(pred, targets) \n",
        "\n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  model2.eval() \n",
        "  y_pred = [] \n",
        "  with torch.no_grad():\n",
        "      for i,data in enumerate(val_dataloader, 0):\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          preds = model2(inputs)\n",
        "          labels = labels.reshape(-1)\n",
        "          loss = criterion(preds,labels)\n",
        "          running_val_loss += loss.item()\n",
        "          \n",
        "      avg_val_loss = running_val_loss/len(val_dataloader)\n",
        "\n",
        "  if avg_val_loss < min_val_loss:\n",
        "      torch.save(model2.state_dict(), PATH)\n",
        "      min_val_loss = avg_val_loss\n",
        "\n",
        "  print(\"epoc :{}, running_loss :{}\".format(epoch,running_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU7bU66vJZAa",
        "outputId": "97823b66-1a39-4839-b3e1-fffaa09e3aab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = Model(Encoder(word_to_idx), Classifier())\n",
        "model2.load_state_dict(torch.load('object_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyvdHjwgJk-v",
        "outputId": "345f0455-1695-46f0-bc58-78b621cc0e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc testing with test data: 45.556385362210605\n"
          ]
        }
      ],
      "source": [
        "## TODO 4.5: evalaute on test set  \n",
        "predict = list()\n",
        "label = al_test\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_test in test_dataloader:\n",
        "        Y_pred = model(X_test)\n",
        "        _, pred = torch.max(Y_pred.data, 1)\n",
        "        for p in pred:\n",
        "            predict.append(p.item())\n",
        "\n",
        "print(\"acc testing with test data:\", sum(predict == label)/len(label) *100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
